# Implementation Plan
**Generated**: 2025-12-03T14:30:00Z
**Task ID**: Issue #25
**Estimated Build Time**: 5-6 hours
**Complexity**: Medium

## Executive Summary
This plan covers the creation of comprehensive E2E tests (Playwright) and component tests (Vitest + React Testing Library) for the feedback submission system. The feedback system has a 6-step state machine (select-type -> describe -> clarify -> submitting -> success/error) with two API endpoints. Current coverage includes 22 unit tests for types/utilities and 1 basic API E2E test. This enhancement adds full UI interaction testing.

## Acceptance Criteria Mapping

| AC | Test Type | Test File | Test Name(s) |
|----|-----------|-----------|--------------|
| Complete bug report submission flow | E2E | feedback-submission.spec.ts | "completes bug submission flow" |
| Complete feature request submission flow | E2E | feedback-submission.spec.ts | "completes feature submission flow" |
| Rate limiting (5/hour) | E2E | feedback-submission.spec.ts | "enforces rate limiting" |
| Error handling - GitHub fail | E2E | feedback-submission.spec.ts | "shows error on GitHub API failure" |
| Error handling - Claude fail | Component | FeedbackDialog.test.tsx | "uses fallback questions when Claude fails" |
| Dialog close/reset behavior | E2E | feedback-submission.spec.ts | "resets form on dialog close/reopen" |
| State transitions (6 steps) | Component | FeedbackDialog.test.tsx | "state machine transitions" suite |
| Form validation (10 char min) | Component | FeedbackDialog.test.tsx | "description validation" suite |
| Answer validation (3 required) | Component | FeedbackDialog.test.tsx | "answer validation" suite |
| Loading states | Component | FeedbackDialog.test.tsx | "loading states" suite |
| Success/error message display | Component | FeedbackDialog.test.tsx | "success/error states" suite |
| Accessibility | Component | FeedbackDialog.test.tsx | "accessibility" suite |

## Phase 1: Component Tests (FeedbackDialog.test.tsx)

### Subtask 1.1: Create Component Test File Structure
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Follow `/home/pbrown/SkuInventory/tests/unit/BuildFooter.test.tsx` (lines 1-64)
**Instructions**:
1. Create file with imports:
   ```typescript
   import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest'
   import { render, screen, fireEvent, waitFor } from '@testing-library/react'
   import userEvent from '@testing-library/user-event'
   import { FeedbackDialog } from '@/components/features/FeedbackDialog'
   ```
2. Mock the sonner toast (avoid side effects):
   ```typescript
   vi.mock('sonner', () => ({
     toast: {
       success: vi.fn(),
       error: vi.fn(),
     },
   }))
   ```
3. Mock fetch for API calls:
   ```typescript
   const mockFetch = vi.fn()
   global.fetch = mockFetch
   ```

**Completion Criteria**:
- [ ] File created in correct location
- [ ] All imports resolve correctly
- [ ] Mocks configured properly
- [ ] TypeScript compiles: `npx tsc --noEmit`

### Subtask 1.2: Test Basic Rendering and Initial State
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Follow BuildFooter.test.tsx rendering tests
**Instructions**:
Add test suite for initial rendering:
```typescript
describe('FeedbackDialog', () => {
  beforeEach(() => {
    mockFetch.mockClear()
  })

  describe('initial rendering', () => {
    it('renders dialog when open is true', () => {
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)
      expect(screen.getByRole('dialog')).toBeInTheDocument()
    })

    it('does not render dialog when open is false', () => {
      render(<FeedbackDialog open={false} onOpenChange={() => {}} />)
      expect(screen.queryByRole('dialog')).not.toBeInTheDocument()
    })

    it('displays "Submit Feedback" title on initial step', () => {
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)
      expect(screen.getByText('Submit Feedback')).toBeInTheDocument()
    })

    it('shows bug and feature type options', () => {
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)
      expect(screen.getByText('Report a Bug')).toBeInTheDocument()
      expect(screen.getByText('Request a Feature')).toBeInTheDocument()
    })
  })
})
```

**Completion Criteria**:
- [ ] All 4 rendering tests pass
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

### Subtask 1.3: Test State Machine Transitions
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Component state machine in FeedbackDialog.tsx (lines 24-55)
**Instructions**:
Add test suite for state transitions:
```typescript
describe('state machine transitions', () => {
  it('transitions from select-type to describe when bug selected', async () => {
    const user = userEvent.setup()
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))

    expect(screen.getByText('Describe the Bug')).toBeInTheDocument()
    expect(screen.getByLabelText('Description *')).toBeInTheDocument()
  })

  it('transitions from select-type to describe when feature selected', async () => {
    const user = userEvent.setup()
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Request a Feature'))

    expect(screen.getByText('Describe Your Feature Request')).toBeInTheDocument()
  })

  it('transitions from describe to clarify after valid description', async () => {
    const user = userEvent.setup()
    mockFetch.mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
      })
    })

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'This is a detailed bug description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })
  })

  it('transitions to error state on submission failure', async () => {
    const user = userEvent.setup()
    mockFetch
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })
      .mockResolvedValueOnce({
        ok: false,
        json: () => Promise.resolve({ message: 'GitHub API failed' })
      })

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    // Complete flow to submission
    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed bug description here')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    // Fill answers
    const textareas = screen.getAllByPlaceholderText('Your answer...')
    await user.type(textareas[0], 'Answer 1')
    await user.type(textareas[1], 'Answer 2')
    await user.type(textareas[2], 'Answer 3')
    await user.click(screen.getByText('Submit Feedback'))

    await waitFor(() => {
      expect(screen.getByText('Submission Failed')).toBeInTheDocument()
    })
  })

  it('transitions to success state on successful submission', async () => {
    const user = userEvent.setup()
    mockFetch
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { issueUrl: 'https://github.com/test/123', issueNumber: 123 }
        })
      })

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed bug description here')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    const textareas = screen.getAllByPlaceholderText('Your answer...')
    await user.type(textareas[0], 'Answer 1')
    await user.type(textareas[1], 'Answer 2')
    await user.type(textareas[2], 'Answer 3')
    await user.click(screen.getByText('Submit Feedback'))

    await waitFor(() => {
      expect(screen.getByText('Thank You!')).toBeInTheDocument()
    })
  })

  it('back button returns from describe to select-type', async () => {
    const user = userEvent.setup()
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    expect(screen.getByText('Describe the Bug')).toBeInTheDocument()

    await user.click(screen.getByText('Back'))
    expect(screen.getByText('Submit Feedback')).toBeInTheDocument()
  })

  it('back button returns from clarify to describe', async () => {
    const user = userEvent.setup()
    mockFetch.mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
      })
    })

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    await user.click(screen.getByText('Back'))
    expect(screen.getByText('Describe the Bug')).toBeInTheDocument()
  })
})
```

**Completion Criteria**:
- [ ] All 7 state transition tests pass
- [ ] Proper async/await handling with waitFor
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

### Subtask 1.4: Test Form Validation
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Validation logic in FeedbackDialog.tsx (lines 57-61, 92-96)
**Instructions**:
Add test suite for form validation:
```typescript
describe('form validation', () => {
  describe('description validation', () => {
    it('displays character count', async () => {
      const user = userEvent.setup()
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      expect(screen.getByText('0/2000 characters (minimum 10)')).toBeInTheDocument()
    })

    it('updates character count as user types', async () => {
      const user = userEvent.setup()
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Test12345')

      expect(screen.getByText('9/2000 characters (minimum 10)')).toBeInTheDocument()
    })

    it('disables Continue button when description < 10 chars', async () => {
      const user = userEvent.setup()
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Short')

      expect(screen.getByRole('button', { name: 'Continue' })).toBeDisabled()
    })

    it('enables Continue button when description >= 10 chars', async () => {
      const user = userEvent.setup()
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'This is enough')

      expect(screen.getByRole('button', { name: 'Continue' })).not.toBeDisabled()
    })

    it('shows error when trying to submit short description', async () => {
      const user = userEvent.setup()
      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Short')

      // Button should be disabled, preventing submission
      const continueBtn = screen.getByRole('button', { name: 'Continue' })
      expect(continueBtn).toBeDisabled()
    })
  })

  describe('answer validation', () => {
    it('disables Submit button when not all answers provided', async () => {
      const user = userEvent.setup()
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      // Only fill 2 of 3 answers
      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')

      expect(screen.getByRole('button', { name: 'Submit Feedback' })).toBeDisabled()
    })

    it('enables Submit button when all answers provided', async () => {
      const user = userEvent.setup()
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')

      expect(screen.getByRole('button', { name: 'Submit Feedback' })).not.toBeDisabled()
    })

    it('displays questions from API response', async () => {
      const user = userEvent.setup()
      mockFetch.mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Custom Q1?', 'Custom Q2?', 'Custom Q3?'] }
        })
      })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('Custom Q1?')).toBeInTheDocument()
        expect(screen.getByText('Custom Q2?')).toBeInTheDocument()
        expect(screen.getByText('Custom Q3?')).toBeInTheDocument()
      })
    })
  })
})
```

**Completion Criteria**:
- [ ] All 8 validation tests pass
- [ ] Button disabled state tested correctly
- [ ] Character count updates verified
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

### Subtask 1.5: Test Loading States
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Loading states in FeedbackDialog.tsx (lines 240-248, 316-320)
**Instructions**:
Add test suite for loading states:
```typescript
describe('loading states', () => {
  it('shows "Getting Questions..." during clarify API call', async () => {
    const user = userEvent.setup()
    // Create a promise we can control
    let resolvePromise: (value: unknown) => void
    const pendingPromise = new Promise((resolve) => {
      resolvePromise = resolve
    })
    mockFetch.mockReturnValueOnce(pendingPromise)

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    expect(screen.getByText('Getting Questions...')).toBeInTheDocument()

    // Cleanup
    resolvePromise!({
      ok: true,
      json: () => Promise.resolve({
        data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
      })
    })
  })

  it('shows spinner during clarify API call', async () => {
    const user = userEvent.setup()
    let resolvePromise: (value: unknown) => void
    const pendingPromise = new Promise((resolve) => {
      resolvePromise = resolve
    })
    mockFetch.mockReturnValueOnce(pendingPromise)

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    // Loader2 icon with animate-spin class indicates loading
    const button = screen.getByRole('button', { name: /Getting Questions/i })
    expect(button).toBeDisabled()

    resolvePromise!({
      ok: true,
      json: () => Promise.resolve({
        data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
      })
    })
  })

  it('shows "Submitting Feedback" step during submission', async () => {
    const user = userEvent.setup()
    let resolveSubmit: (value: unknown) => void
    const pendingSubmit = new Promise((resolve) => {
      resolveSubmit = resolve
    })

    mockFetch
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })
      .mockReturnValueOnce(pendingSubmit)

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    const textareas = screen.getAllByPlaceholderText('Your answer...')
    await user.type(textareas[0], 'Answer 1')
    await user.type(textareas[1], 'Answer 2')
    await user.type(textareas[2], 'Answer 3')
    await user.click(screen.getByText('Submit Feedback'))

    expect(screen.getByText('Submitting Feedback')).toBeInTheDocument()
    expect(screen.getByText('Creating your GitHub issue...')).toBeInTheDocument()

    resolveSubmit!({
      ok: true,
      json: () => Promise.resolve({
        data: { issueUrl: 'https://github.com/test/123', issueNumber: 123 }
      })
    })
  })

  it('shows "Please wait..." message during submission', async () => {
    const user = userEvent.setup()
    let resolveSubmit: (value: unknown) => void
    const pendingSubmit = new Promise((resolve) => {
      resolveSubmit = resolve
    })

    mockFetch
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })
      .mockReturnValueOnce(pendingSubmit)

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    const textareas = screen.getAllByPlaceholderText('Your answer...')
    await user.type(textareas[0], 'Answer 1')
    await user.type(textareas[1], 'Answer 2')
    await user.type(textareas[2], 'Answer 3')
    await user.click(screen.getByText('Submit Feedback'))

    expect(screen.getByText('Please wait...')).toBeInTheDocument()

    resolveSubmit!({
      ok: true,
      json: () => Promise.resolve({
        data: { issueUrl: 'https://github.com/test/123', issueNumber: 123 }
      })
    })
  })
})
```

**Completion Criteria**:
- [ ] All 4 loading state tests pass
- [ ] Loading text verified
- [ ] Spinner/disabled button state tested
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

### Subtask 1.6: Test Success and Error States
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Success/error states in FeedbackDialog.tsx (lines 323-384)
**Instructions**:
Add test suite for success/error states:
```typescript
describe('success and error states', () => {
  describe('success state', () => {
    it('displays "Thank You!" message on success', async () => {
      const user = userEvent.setup()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { issueUrl: 'https://github.com/test/123', issueNumber: 123 }
          })
        })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        expect(screen.getByText('Thank You!')).toBeInTheDocument()
      })
    })

    it('displays issue URL link on success', async () => {
      const user = userEvent.setup()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { issueUrl: 'https://github.com/owner/repo/issues/123', issueNumber: 123 }
          })
        })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        const link = screen.getByRole('link', { name: 'View Issue' })
        expect(link).toBeInTheDocument()
        expect(link).toHaveAttribute('href', 'https://github.com/owner/repo/issues/123')
        expect(link).toHaveAttribute('target', '_blank')
      })
    })

    it('shows Close button on success', async () => {
      const user = userEvent.setup()
      const mockOnOpenChange = vi.fn()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { issueUrl: 'https://github.com/test/123', issueNumber: 123 }
          })
        })

      render(<FeedbackDialog open={true} onOpenChange={mockOnOpenChange} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        expect(screen.getByText('Thank You!')).toBeInTheDocument()
      })

      await user.click(screen.getByRole('button', { name: 'Close' }))
      expect(mockOnOpenChange).toHaveBeenCalledWith(false)
    })
  })

  describe('error state', () => {
    it('displays "Submission Failed" on error', async () => {
      const user = userEvent.setup()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: false,
          json: () => Promise.resolve({ message: 'GitHub API failed' })
        })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        expect(screen.getByText('Submission Failed')).toBeInTheDocument()
      })
    })

    it('displays error message from API', async () => {
      const user = userEvent.setup()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: false,
          json: () => Promise.resolve({ message: 'Rate limit exceeded' })
        })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        expect(screen.getByText('Rate limit exceeded')).toBeInTheDocument()
      })
    })

    it('shows Cancel and Try Again buttons on error', async () => {
      const user = userEvent.setup()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: false,
          json: () => Promise.resolve({ message: 'Error' })
        })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        expect(screen.getByText('Submission Failed')).toBeInTheDocument()
      })

      expect(screen.getByRole('button', { name: 'Cancel' })).toBeInTheDocument()
      expect(screen.getByRole('button', { name: 'Try Again' })).toBeInTheDocument()
    })

    it('Try Again returns to clarify step', async () => {
      const user = userEvent.setup()
      mockFetch
        .mockResolvedValueOnce({
          ok: true,
          json: () => Promise.resolve({
            data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
          })
        })
        .mockResolvedValueOnce({
          ok: false,
          json: () => Promise.resolve({ message: 'Error' })
        })

      render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

      await user.click(screen.getByText('Report a Bug'))
      await user.type(screen.getByLabelText('Description *'), 'Detailed description')
      await user.click(screen.getByText('Continue'))

      await waitFor(() => {
        expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
      })

      const textareas = screen.getAllByPlaceholderText('Your answer...')
      await user.type(textareas[0], 'Answer 1')
      await user.type(textareas[1], 'Answer 2')
      await user.type(textareas[2], 'Answer 3')
      await user.click(screen.getByText('Submit Feedback'))

      await waitFor(() => {
        expect(screen.getByText('Submission Failed')).toBeInTheDocument()
      })

      await user.click(screen.getByRole('button', { name: 'Try Again' }))
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })
  })
})
```

**Completion Criteria**:
- [ ] All 7 success/error state tests pass
- [ ] Issue URL link verified
- [ ] Error messages displayed correctly
- [ ] Try Again functionality verified
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

### Subtask 1.7: Test Accessibility
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: ARIA attributes in FeedbackDialog.tsx
**Instructions**:
Add test suite for accessibility:
```typescript
describe('accessibility', () => {
  it('dialog has role="dialog"', () => {
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)
    expect(screen.getByRole('dialog')).toBeInTheDocument()
  })

  it('form inputs have associated labels', async () => {
    const user = userEvent.setup()
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))

    const textarea = screen.getByLabelText('Description *')
    expect(textarea).toBeInTheDocument()
    expect(textarea.tagName.toLowerCase()).toBe('textarea')
  })

  it('answer textareas have proper labels', async () => {
    const user = userEvent.setup()
    mockFetch.mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        data: { questions: ['Question 1?', 'Question 2?', 'Question 3?'] }
      })
    })

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('Question 1?')).toBeInTheDocument()
    })

    // Each question serves as a label for its textarea
    const q1Label = screen.getByText('Question 1?')
    expect(q1Label.tagName.toLowerCase()).toBe('label')
  })

  it('type selection buttons are keyboard accessible', async () => {
    const user = userEvent.setup()
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    const bugButton = screen.getByText('Report a Bug').closest('button')
    const featureButton = screen.getByText('Request a Feature').closest('button')

    expect(bugButton).toHaveAttribute('type', 'button')
    expect(featureButton).toHaveAttribute('type', 'button')
  })

  it('error messages are visible to screen readers', async () => {
    const user = userEvent.setup()
    mockFetch
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })
      .mockResolvedValueOnce({
        ok: false,
        json: () => Promise.resolve({ message: 'API Error' })
      })

    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    const textareas = screen.getAllByPlaceholderText('Your answer...')
    await user.type(textareas[0], 'Answer 1')
    await user.type(textareas[1], 'Answer 2')
    await user.type(textareas[2], 'Answer 3')
    await user.click(screen.getByText('Submit Feedback'))

    await waitFor(() => {
      // Error message should be visible
      expect(screen.getByText('API Error')).toBeInTheDocument()
    })
  })

  it('dialog has proper title and description', () => {
    render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    expect(screen.getByText('Submit Feedback')).toBeInTheDocument()
    expect(screen.getByText('Help us improve! What type of feedback do you have?')).toBeInTheDocument()
  })
})
```

**Completion Criteria**:
- [ ] All 6 accessibility tests pass
- [ ] Dialog roles verified
- [ ] Labels associated correctly
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

### Subtask 1.8: Test Dialog Reset Behavior
**File**: `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx`
**Pattern**: Reset logic in FeedbackDialog.tsx (lines 36-50)
**Instructions**:
Add test suite for dialog reset:
```typescript
describe('dialog reset behavior', () => {
  it('resets to select-type step when dialog closes', async () => {
    const user = userEvent.setup()
    const { rerender } = render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    // Navigate to describe step
    await user.click(screen.getByText('Report a Bug'))
    expect(screen.getByText('Describe the Bug')).toBeInTheDocument()

    // Close dialog
    rerender(<FeedbackDialog open={false} onOpenChange={() => {}} />)

    // Wait for reset (200ms delay in component)
    await waitFor(() => {
      // Reopen and verify reset
      rerender(<FeedbackDialog open={true} onOpenChange={() => {}} />)
    }, { timeout: 300 })

    expect(screen.getByText('Submit Feedback')).toBeInTheDocument()
    expect(screen.getByText('Report a Bug')).toBeInTheDocument()
  })

  it('clears description when dialog closes', async () => {
    const user = userEvent.setup()
    const { rerender } = render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Test description')

    expect(screen.getByDisplayValue('Test description')).toBeInTheDocument()

    rerender(<FeedbackDialog open={false} onOpenChange={() => {}} />)

    await new Promise(resolve => setTimeout(resolve, 250))

    rerender(<FeedbackDialog open={true} onOpenChange={() => {}} />)
    await user.click(screen.getByText('Report a Bug'))

    expect(screen.getByLabelText('Description *')).toHaveValue('')
  })

  it('clears error state when dialog closes', async () => {
    const user = userEvent.setup()
    mockFetch
      .mockResolvedValueOnce({
        ok: true,
        json: () => Promise.resolve({
          data: { questions: ['Q1?', 'Q2?', 'Q3?'] }
        })
      })
      .mockResolvedValueOnce({
        ok: false,
        json: () => Promise.resolve({ message: 'Test Error' })
      })

    const { rerender } = render(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    // Navigate to error state
    await user.click(screen.getByText('Report a Bug'))
    await user.type(screen.getByLabelText('Description *'), 'Detailed description')
    await user.click(screen.getByText('Continue'))

    await waitFor(() => {
      expect(screen.getByText('A Few Quick Questions')).toBeInTheDocument()
    })

    const textareas = screen.getAllByPlaceholderText('Your answer...')
    await user.type(textareas[0], 'Answer 1')
    await user.type(textareas[1], 'Answer 2')
    await user.type(textareas[2], 'Answer 3')
    await user.click(screen.getByText('Submit Feedback'))

    await waitFor(() => {
      expect(screen.getByText('Submission Failed')).toBeInTheDocument()
    })

    // Close and reopen
    rerender(<FeedbackDialog open={false} onOpenChange={() => {}} />)
    await new Promise(resolve => setTimeout(resolve, 250))
    rerender(<FeedbackDialog open={true} onOpenChange={() => {}} />)

    expect(screen.getByText('Submit Feedback')).toBeInTheDocument()
    expect(screen.queryByText('Submission Failed')).not.toBeInTheDocument()
    expect(screen.queryByText('Test Error')).not.toBeInTheDocument()
  })
})
```

**Completion Criteria**:
- [ ] All 3 reset behavior tests pass
- [ ] State reset verified after close
- [ ] Tests run: `npm test -- --filter="FeedbackDialog"`

## Phase 2: E2E Tests (feedback-submission.spec.ts)

### Subtask 2.1: Create E2E Test File Structure
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Pattern**: Follow `/home/pbrown/SkuInventory/tests/e2e/build-dialog-error-handling.spec.ts` (lines 1-22)
**Instructions**:
1. Create file with imports and login pattern:
   ```typescript
   import { test, expect } from '@playwright/test'

   /**
    * Feedback Submission E2E Tests
    *
    * Tests for Issue #25: Comprehensive E2E testing for feedback dialog
    *
    * These tests verify:
    * - Complete bug and feature submission flows
    * - Rate limiting (5 submissions per hour)
    * - Error handling scenarios
    * - Dialog close/reset behavior
    */
   test.describe('Feedback Submission', () => {
     test.beforeEach(async ({ page }) => {
       // Login as admin
       await page.goto('/login')
       await page.waitForSelector('#email', { timeout: 10000 })
       await page.fill('#email', 'admin@tonsil.tech')
       await page.fill('#password', 'changeme123')
       await page.click('button[type="submit"]')
       await page.waitForURL('/', { timeout: 15000 })
     })
   })
   ```

**Completion Criteria**:
- [ ] File created in correct location
- [ ] Login pattern matches existing tests
- [ ] File compiles without errors

### Subtask 2.2: Add Helper Functions
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Pattern**: Reusable E2E helpers
**Instructions**:
Add helper functions after imports:
```typescript
// Helper to open feedback dialog
async function openFeedbackDialog(page: import('@playwright/test').Page) {
  // The feedback button is in the header (MessageSquare icon with title="Submit Feedback")
  const feedbackBtn = page.locator('button[title="Submit Feedback"]')
  await expect(feedbackBtn).toBeVisible({ timeout: 5000 })
  await feedbackBtn.click()
  await expect(page.locator('[role="dialog"]')).toBeVisible({ timeout: 5000 })
}

// Helper to complete a full submission flow
async function completeFeedbackSubmission(
  page: import('@playwright/test').Page,
  type: 'bug' | 'feature',
  description: string
) {
  const dialog = page.locator('[role="dialog"]')

  // Step 1: Select type
  const typeButton = type === 'bug'
    ? dialog.locator('button:has-text("Report a Bug")')
    : dialog.locator('button:has-text("Request a Feature")')
  await typeButton.click()

  // Step 2: Enter description
  const descriptionField = dialog.locator('textarea#description')
  await descriptionField.fill(description)
  await dialog.locator('button:has-text("Continue")').click()

  // Step 3: Wait for questions and answer them
  await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible({ timeout: 10000 })

  const answerFields = dialog.locator('textarea[placeholder="Your answer..."]')
  await answerFields.nth(0).fill('Test answer 1 for E2E testing')
  await answerFields.nth(1).fill('Test answer 2 for E2E testing')
  await answerFields.nth(2).fill('Test answer 3 for E2E testing')

  // Submit
  await dialog.locator('button:has-text("Submit Feedback")').click()
}
```

**Completion Criteria**:
- [ ] Helper functions added
- [ ] TypeScript types correct
- [ ] Functions are reusable

### Subtask 2.3: Test Bug Submission Flow
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Pattern**: Multi-step dialog flows
**Instructions**:
Add test for bug submission:
```typescript
test.describe('bug submission flow', () => {
  test('completes full bug submission and creates GitHub issue', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    // Verify initial state
    await expect(dialog.locator('text=Submit Feedback')).toBeVisible()
    await expect(dialog.locator('text=Report a Bug')).toBeVisible()
    await expect(dialog.locator('text=Request a Feature')).toBeVisible()

    // Select bug type
    await dialog.locator('button:has-text("Report a Bug")').click()

    // Verify describe step
    await expect(dialog.locator('text=Describe the Bug')).toBeVisible()

    // Enter description
    const descriptionField = dialog.locator('textarea#description')
    const testDescription = 'E2E TEST BUG - Please close. Testing feedback E2E flow via Playwright ' + Date.now()
    await descriptionField.fill(testDescription)

    // Verify character count updates
    await expect(dialog.locator('text=/\\d+\\/2000 characters/')).toBeVisible()

    // Continue to clarify
    await dialog.locator('button:has-text("Continue")').click()

    // Wait for questions (may take time if Claude API is called)
    await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible({ timeout: 15000 })

    // Answer all questions
    const answerFields = dialog.locator('textarea[placeholder="Your answer..."]')
    await expect(answerFields).toHaveCount(3)

    await answerFields.nth(0).fill('E2E test reproduction steps')
    await answerFields.nth(1).fill('E2E test expected behavior')
    await answerFields.nth(2).fill('E2E test when noticed')

    // Submit
    await dialog.locator('button:has-text("Submit Feedback")').click()

    // Verify submitting state
    await expect(dialog.locator('text=Submitting Feedback')).toBeVisible({ timeout: 5000 })

    // Verify success (may take time for GitHub API)
    await expect(dialog.locator('text=Thank You!')).toBeVisible({ timeout: 30000 })

    // Verify issue URL is displayed
    const issueLink = dialog.locator('a:has-text("View Issue")')
    await expect(issueLink).toBeVisible()
    expect(await issueLink.getAttribute('href')).toContain('github.com')

    // Close dialog
    await dialog.locator('button:has-text("Close")').click()
    await expect(dialog).not.toBeVisible({ timeout: 3000 })
  })

  test('validates description minimum length', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    await dialog.locator('button:has-text("Report a Bug")').click()

    // Enter short description
    const descriptionField = dialog.locator('textarea#description')
    await descriptionField.fill('Short')

    // Continue button should be disabled
    const continueBtn = dialog.locator('button:has-text("Continue")')
    await expect(continueBtn).toBeDisabled()

    // Enter valid description
    await descriptionField.fill('This is a valid description that meets the minimum length')
    await expect(continueBtn).not.toBeDisabled()
  })
})
```

**Completion Criteria**:
- [ ] Bug submission flow test passes
- [ ] Description validation test passes
- [ ] GitHub issue created (check GitHub)
- [ ] Tests run: `npx playwright test feedback-submission --grep="bug submission"`

### Subtask 2.4: Test Feature Submission Flow
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Instructions**:
Add test for feature submission:
```typescript
test.describe('feature submission flow', () => {
  test('completes full feature submission and creates GitHub issue', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    // Select feature type
    await dialog.locator('button:has-text("Request a Feature")').click()

    // Verify describe step shows feature-specific UI
    await expect(dialog.locator('text=Describe Your Feature Request')).toBeVisible()

    // Enter description
    const descriptionField = dialog.locator('textarea#description')
    const testDescription = 'E2E TEST FEATURE - Please close. Testing feature request E2E flow ' + Date.now()
    await descriptionField.fill(testDescription)

    // Continue to clarify
    await dialog.locator('button:has-text("Continue")').click()

    // Wait for questions
    await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible({ timeout: 15000 })

    // Answer all questions
    const answerFields = dialog.locator('textarea[placeholder="Your answer..."]')
    await answerFields.nth(0).fill('E2E test problem this would solve')
    await answerFields.nth(1).fill('E2E test how I would use it')
    await answerFields.nth(2).fill('E2E test importance level')

    // Submit
    await dialog.locator('button:has-text("Submit Feedback")').click()

    // Verify success
    await expect(dialog.locator('text=Thank You!')).toBeVisible({ timeout: 30000 })

    // Verify issue URL
    const issueLink = dialog.locator('a:has-text("View Issue")')
    await expect(issueLink).toBeVisible()
    expect(await issueLink.getAttribute('href')).toContain('github.com')

    // Close dialog
    await dialog.locator('button:has-text("Close")').click()
    await expect(dialog).not.toBeVisible({ timeout: 3000 })
  })
})
```

**Completion Criteria**:
- [ ] Feature submission flow test passes
- [ ] Feature-specific UI verified
- [ ] GitHub issue created with enhancement label
- [ ] Tests run: `npx playwright test feedback-submission --grep="feature submission"`

### Subtask 2.5: Test Rate Limiting
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Pattern**: Rate limit logic in route.ts (lines 17-32)
**Instructions**:
Add test for rate limiting:
```typescript
test.describe('rate limiting', () => {
  test.skip('enforces 5 submissions per hour limit', async ({ page }) => {
    // NOTE: This test is skipped by default because:
    // 1. It creates real GitHub issues
    // 2. It requires 6 API calls which is slow
    // 3. Rate limiting is in-memory and resets on server restart
    //
    // To run manually: remove .skip and run in isolation
    // After test, manually close the test issues on GitHub

    // Submit 5 feedback items successfully
    for (let i = 0; i < 5; i++) {
      await openFeedbackDialog(page)
      await completeFeedbackSubmission(
        page,
        'bug',
        `Rate limit test ${i + 1}/5 - Please close - ${Date.now()}`
      )

      await expect(page.locator('[role="dialog"]').locator('text=Thank You!')).toBeVisible({ timeout: 30000 })
      await page.locator('[role="dialog"]').locator('button:has-text("Close")').click()
      await expect(page.locator('[role="dialog"]')).not.toBeVisible({ timeout: 3000 })
    }

    // 6th submission should fail with rate limit error
    await openFeedbackDialog(page)
    await completeFeedbackSubmission(
      page,
      'bug',
      'Rate limit test 6/6 - Should fail - ' + Date.now()
    )

    const dialog = page.locator('[role="dialog"]')
    await expect(dialog.locator('text=Submission Failed')).toBeVisible({ timeout: 30000 })
    await expect(dialog.locator('text=/rate limit/i')).toBeVisible()
  })
})
```

**Note**: This test is intentionally marked as `.skip` because:
- It creates 6 real GitHub issues
- Rate limiting is in-memory (resets on server restart)
- Can be run manually when specifically testing rate limits

**Completion Criteria**:
- [ ] Test structure correct (even if skipped)
- [ ] Rate limit error detection logic correct
- [ ] Manual run possible when needed

### Subtask 2.6: Test Error Handling
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Instructions**:
Add tests for error handling:
```typescript
test.describe('error handling', () => {
  test('shows error state and retry option on submission failure', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    // Complete flow normally
    await dialog.locator('button:has-text("Report a Bug")').click()
    await dialog.locator('textarea#description').fill('E2E error handling test - ' + Date.now())
    await dialog.locator('button:has-text("Continue")').click()

    await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible({ timeout: 15000 })

    const answerFields = dialog.locator('textarea[placeholder="Your answer..."]')
    await answerFields.nth(0).fill('Answer 1')
    await answerFields.nth(1).fill('Answer 2')
    await answerFields.nth(2).fill('Answer 3')

    // Intercept the API call to force an error
    await page.route('**/api/feedback', async (route) => {
      await route.fulfill({
        status: 500,
        contentType: 'application/json',
        body: JSON.stringify({ message: 'Simulated server error for testing' }),
      })
    })

    await dialog.locator('button:has-text("Submit Feedback")').click()

    // Verify error state
    await expect(dialog.locator('text=Submission Failed')).toBeVisible({ timeout: 10000 })
    await expect(dialog.locator('text=Simulated server error for testing')).toBeVisible()

    // Verify retry options
    await expect(dialog.locator('button:has-text("Cancel")')).toBeVisible()
    await expect(dialog.locator('button:has-text("Try Again")')).toBeVisible()

    // Test Try Again returns to clarify step
    await page.unroute('**/api/feedback')
    await dialog.locator('button:has-text("Try Again")').click()
    await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible()
  })

  test('handles clarify API failure gracefully', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    // Intercept clarify API to return error
    await page.route('**/api/feedback/clarify', async (route) => {
      await route.fulfill({
        status: 500,
        contentType: 'application/json',
        body: JSON.stringify({ message: 'Clarify API unavailable' }),
      })
    })

    await dialog.locator('button:has-text("Report a Bug")').click()
    await dialog.locator('textarea#description').fill('Testing clarify API failure handling')
    await dialog.locator('button:has-text("Continue")').click()

    // Should show error message
    await expect(dialog.locator('text=Clarify API unavailable')).toBeVisible({ timeout: 10000 })
  })

  test('Cancel button closes dialog on error state', async ({ page }) => {
    const mockOnClose = async () => {
      await openFeedbackDialog(page)
      const dialog = page.locator('[role="dialog"]')

      await dialog.locator('button:has-text("Report a Bug")').click()
      await dialog.locator('textarea#description').fill('Test cancel on error')
      await dialog.locator('button:has-text("Continue")').click()

      await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible({ timeout: 15000 })

      const answerFields = dialog.locator('textarea[placeholder="Your answer..."]')
      await answerFields.nth(0).fill('Answer 1')
      await answerFields.nth(1).fill('Answer 2')
      await answerFields.nth(2).fill('Answer 3')

      await page.route('**/api/feedback', async (route) => {
        await route.fulfill({
          status: 500,
          contentType: 'application/json',
          body: JSON.stringify({ message: 'Error' }),
        })
      })

      await dialog.locator('button:has-text("Submit Feedback")').click()
      await expect(dialog.locator('text=Submission Failed')).toBeVisible({ timeout: 10000 })

      await dialog.locator('button:has-text("Cancel")').click()
      await expect(dialog).not.toBeVisible({ timeout: 3000 })
    }

    await mockOnClose()
  })
})
```

**Completion Criteria**:
- [ ] Error state display test passes
- [ ] Clarify API failure test passes
- [ ] Cancel button test passes
- [ ] API route interception works correctly
- [ ] Tests run: `npx playwright test feedback-submission --grep="error handling"`

### Subtask 2.7: Test Dialog Close/Reset Behavior
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Instructions**:
Add tests for dialog reset:
```typescript
test.describe('dialog close and reset', () => {
  test('resets form when dialog is closed and reopened', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    // Navigate to describe step and enter data
    await dialog.locator('button:has-text("Report a Bug")').click()
    await dialog.locator('textarea#description').fill('Test description to verify reset')

    // Close dialog using X button or clicking outside
    await page.keyboard.press('Escape')
    await expect(dialog).not.toBeVisible({ timeout: 3000 })

    // Wait for reset timeout (200ms in component)
    await page.waitForTimeout(300)

    // Reopen dialog
    await openFeedbackDialog(page)

    // Should be back at select-type step
    await expect(dialog.locator('text=Submit Feedback')).toBeVisible()
    await expect(dialog.locator('text=Report a Bug')).toBeVisible()
    await expect(dialog.locator('text=Request a Feature')).toBeVisible()
  })

  test('back button works correctly through all steps', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    // Go to describe step
    await dialog.locator('button:has-text("Report a Bug")').click()
    await expect(dialog.locator('text=Describe the Bug')).toBeVisible()

    // Back to select-type
    await dialog.locator('button:has-text("Back")').click()
    await expect(dialog.locator('text=Submit Feedback')).toBeVisible()

    // Go through to clarify step
    await dialog.locator('button:has-text("Report a Bug")').click()
    await dialog.locator('textarea#description').fill('Testing back button navigation')
    await dialog.locator('button:has-text("Continue")').click()

    await expect(dialog.locator('text=A Few Quick Questions')).toBeVisible({ timeout: 15000 })

    // Back to describe
    await dialog.locator('button:has-text("Back")').click()
    await expect(dialog.locator('text=Describe the Bug')).toBeVisible()

    // Description should still be there
    await expect(dialog.locator('textarea#description')).toHaveValue('Testing back button navigation')
  })

  test('dialog can be closed via Escape key', async ({ page }) => {
    await openFeedbackDialog(page)
    const dialog = page.locator('[role="dialog"]')

    await expect(dialog).toBeVisible()
    await page.keyboard.press('Escape')
    await expect(dialog).not.toBeVisible({ timeout: 3000 })
  })
})
```

**Completion Criteria**:
- [ ] Reset on reopen test passes
- [ ] Back button navigation test passes
- [ ] Escape key close test passes
- [ ] Tests run: `npx playwright test feedback-submission --grep="close and reset"`

### Subtask 2.8: Test FeedbackButton Visibility
**File**: `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts`
**Pattern**: Button placement in layout.tsx (line 126)
**Instructions**:
Add test for button visibility:
```typescript
test.describe('feedback button', () => {
  test('feedback button is visible in header', async ({ page }) => {
    // Already logged in from beforeEach
    const feedbackBtn = page.locator('button[title="Submit Feedback"]')
    await expect(feedbackBtn).toBeVisible({ timeout: 5000 })
  })

  test('feedback button has correct aria-label', async ({ page }) => {
    const feedbackBtn = page.locator('button[title="Submit Feedback"]')
    await expect(feedbackBtn).toHaveAttribute('aria-label', 'Submit Feedback')
  })

  test('feedback button opens dialog on click', async ({ page }) => {
    const feedbackBtn = page.locator('button[title="Submit Feedback"]')
    await feedbackBtn.click()

    const dialog = page.locator('[role="dialog"]')
    await expect(dialog).toBeVisible({ timeout: 5000 })
    await expect(dialog.locator('text=Submit Feedback')).toBeVisible()
  })
})
```

**Completion Criteria**:
- [ ] Button visibility test passes
- [ ] Button aria-label test passes
- [ ] Button click opens dialog test passes
- [ ] Tests run: `npx playwright test feedback-submission --grep="feedback button"`

## Phase 3: Final Validation

### Subtask 3.1: Run All Component Tests
**Instructions**:
```bash
npm test -- --filter="FeedbackDialog"
```

**Completion Criteria**:
- [ ] All component tests pass
- [ ] No test failures
- [ ] Coverage includes all state transitions

### Subtask 3.2: Run All E2E Tests
**Instructions**:
```bash
npx playwright test feedback-submission
```

**Completion Criteria**:
- [ ] All E2E tests pass (except intentionally skipped rate limit test)
- [ ] No flaky tests
- [ ] GitHub issues created for happy path tests (close them after)

### Subtask 3.3: Full Test Suite Validation
**Instructions**:
```bash
npm run build
npx tsc --noEmit
npm test
npm run test:e2e
```

**Completion Criteria**:
- [ ] Build succeeds
- [ ] TypeScript compiles without errors
- [ ] All unit tests pass
- [ ] All E2E tests pass

## Summary of Deliverables

**Files Created**:
- `/home/pbrown/SkuInventory/tests/unit/FeedbackDialog.test.tsx` (~400-450 lines)
- `/home/pbrown/SkuInventory/tests/e2e/feedback-submission.spec.ts` (~350-400 lines)

**Files Modified**: None (test-only enhancement)

**Test Count**:
- Component tests: ~35 tests across 8 suites
- E2E tests: ~15 tests across 5 suites

**Coverage Added**:
- FeedbackDialog state machine (6 steps)
- Form validation (description + answers)
- Loading states (clarify + submit)
- Success/error message display
- Dialog reset behavior
- Accessibility (roles, labels, keyboard)
- Rate limiting (structure, manual run)
- E2E happy paths (bug + feature submission)
- E2E error handling (API failures, retry)

## Handoff to Build Agent

1. Execute subtasks in exact order (Phase 1 before Phase 2)
2. For component tests: mock fetch and sonner before each test
3. For E2E tests: ensure app is running at http://172.16.20.50:4545
4. Test completion criteria after each subtask
5. Follow reference patterns exactly (BuildFooter.test.tsx for unit, build-dialog-error-handling.spec.ts for E2E)
6. After successful E2E tests, manually close any test GitHub issues created

**Important Notes**:
- Rate limit test is intentionally skipped (creates real issues)
- E2E tests create real GitHub issues - close them after testing
- Component tests mock all API calls - no real network requests
- Use `userEvent` for component tests (more realistic than fireEvent)

## Performance Metrics
| Phase | Duration |
|-------|----------|
| Scout Review | 5m |
| Pattern Research | 8m |
| Plan Writing | 18m |
| **Total** | **31m** |
